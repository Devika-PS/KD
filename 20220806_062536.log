2022-08-06 06:25:36,191 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA GeForce GTX 1650
CUDA_HOME: /usr/local/cuda-11.7
GCC: gcc (Ubuntu 11.2.0-19ubuntu1) 11.2.0
PyTorch: 1.12.0
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.0
OpenCV: 4.6.0
MMCV: 1.6.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMClassification: 0.23.1+d2e5054
------------------------------------------------------------

2022-08-06 06:25:36,191 - mmcls - INFO - Distributed training: False
2022-08-06 06:25:36,364 - mmcls - INFO - Config:
dataset_type = 'CIFAR100'
img_norm_cfg = dict(
    mean=[129.304, 124.07, 112.434], std=[68.17, 65.392, 70.418], to_rgb=False)
train_pipeline = [
    dict(type='RandomCrop', size=32, padding=4),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='Normalize',
        mean=[129.304, 124.07, 112.434],
        std=[68.17, 65.392, 70.418],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(
        type='Normalize',
        mean=[129.304, 124.07, 112.434],
        std=[68.17, 65.392, 70.418],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=128,
    workers_per_gpu=3,
    train=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(type='RandomCrop', size=32, padding=4),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CIFAR100',
        data_prefix='data/cifar100',
        pipeline=[
            dict(
                type='Normalize',
                mean=[129.304, 124.07, 112.434],
                std=[68.17, 65.392, 70.418],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
checkpoint_config = dict(interval=10)
log_config = dict(
    interval=100,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = './Student_BSS_8_cifar100_again_005/'
optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[60, 120, 150], gamma=0.2)
runner = dict(type='EpochBasedRunner', max_epochs=200)
model = dict(
    type='BaseClassifier_BSS',
    kd_loss=dict(type='KD_loss_BSS', Temperature=3.0),
    train_cfg=dict(
        teacher_checkpoint=
        '/home/mushti/mmlab/mmclassification/Teacher_100_again/epoch_200.pth',
        max_epoch=200,
        attack_size=64),
    backbone=dict(
        student=dict(
            type='ResNet_CIFAR',
            depth=8,
            num_stages=4,
            out_indices=(3, ),
            style='pytorch'),
        teacher=dict(
            type='ResNet_CIFAR',
            depth=34,
            num_stages=4,
            out_indices=(3, ),
            style='pytorch')),
    neck=dict(
        student=dict(type='GlobalAveragePooling'),
        teacher=dict(type='GlobalAveragePooling')),
    head=dict(
        student=dict(
            type='LinearClsHead',
            num_classes=100,
            in_channels=512,
            loss=dict(type='CrossEntropyLoss', loss_weight=1.0)),
        teacher=dict(
            type='LinearClsHead',
            num_classes=100,
            in_channels=512,
            loss=dict(type='CrossEntropyLoss', loss_weight=1.0))))
gpu_ids = [0]

2022-08-06 06:25:36,364 - mmcls - INFO - Set random seed to 1387808760, deterministic: False
Name of parameter - Initialization information

student.backbone.conv1.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.head.fc.weight - torch.Size([100, 512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

student.head.fc.bias - torch.Size([100]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.conv1.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.2.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.2.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.3.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.2.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.3.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.4.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.5.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.head.fc.weight - torch.Size([100, 512]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  

teacher.head.fc.bias - torch.Size([100]): 
The value is the same before and after calling `init_weights` of BaseClassifier_BSS  
2022-08-06 06:25:38,636 - mmcls - INFO - Start running, host: mushti@mushti-Nitro-AN515-43, work_dir: /home/mushti/mmlab/mmclassification/Student_BSS_8_cifar100_again_005
2022-08-06 06:25:38,636 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-08-06 06:25:38,636 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2022-08-06 06:25:38,636 - mmcls - INFO - Checkpoints will be saved to /home/mushti/mmlab/mmclassification/Student_BSS_8_cifar100_again_005 by HardDiskBackend.
2022-08-06 06:26:32,949 - mmcls - INFO - Epoch [1][100/391]	lr: 1.000e-03, eta: 11:44:29, time: 0.541, data_time: 0.021, memory: 1231, loss: 31.0842, loss_KD: 26.7353
2022-08-06 06:27:38,963 - mmcls - INFO - Epoch [1][200/391]	lr: 1.000e-03, eta: 13:00:52, time: 0.660, data_time: 0.002, memory: 1231, loss: 30.8293, loss_KD: 26.8951
2022-08-06 06:28:54,333 - mmcls - INFO - Epoch [1][300/391]	lr: 1.000e-03, eta: 14:06:06, time: 0.754, data_time: 0.002, memory: 1231, loss: 30.4734, loss_KD: 26.7422
2022-08-06 06:30:15,200 - mmcls - INFO - Epoch(val) [1][79]	accuracy_top-1: 16.6600, accuracy_top-5: 42.0900
2022-08-06 06:31:39,648 - mmcls - INFO - Epoch [2][100/391]	lr: 1.000e-03, eta: 12:18:03, time: 0.843, data_time: 0.021, memory: 1247, loss: 30.0392, loss_KD: 26.5774
2022-08-06 06:33:18,019 - mmcls - INFO - Epoch [2][200/391]	lr: 1.000e-03, eta: 13:47:40, time: 0.984, data_time: 0.002, memory: 1315, loss: 29.8338, loss_KD: 26.4931
2022-08-06 06:34:54,338 - mmcls - INFO - Epoch [2][300/391]	lr: 1.000e-03, eta: 14:47:12, time: 0.964, data_time: 0.002, memory: 1315, loss: 29.5900, loss_KD: 26.3901
2022-08-06 06:36:47,956 - mmcls - INFO - Epoch(val) [2][79]	accuracy_top-1: 25.7300, accuracy_top-5: 56.2600
2022-08-06 06:38:43,794 - mmcls - INFO - Epoch [3][100/391]	lr: 1.000e-03, eta: 14:22:31, time: 1.158, data_time: 0.021, memory: 1393, loss: 29.1984, loss_KD: 26.2509
2022-08-06 06:40:31,246 - mmcls - INFO - Epoch [3][200/391]	lr: 1.000e-03, eta: 15:14:23, time: 1.074, data_time: 0.001, memory: 1393, loss: 29.1006, loss_KD: 26.2067
2022-08-06 06:42:36,093 - mmcls - INFO - Epoch [3][300/391]	lr: 1.000e-03, eta: 16:17:06, time: 1.248, data_time: 0.002, memory: 1393, loss: 28.9197, loss_KD: 26.1315
2022-08-06 06:44:33,006 - mmcls - INFO - Epoch(val) [3][79]	accuracy_top-1: 29.8200, accuracy_top-5: 62.4600
2022-08-06 06:46:52,257 - mmcls - INFO - Epoch [4][100/391]	lr: 1.000e-03, eta: 16:08:36, time: 1.392, data_time: 0.021, memory: 1436, loss: 28.6430, loss_KD: 26.0209
2022-08-06 06:48:59,358 - mmcls - INFO - Epoch [4][200/391]	lr: 1.000e-03, eta: 16:55:21, time: 1.270, data_time: 0.001, memory: 1436, loss: 28.5929, loss_KD: 26.0073
2022-08-06 06:51:21,221 - mmcls - INFO - Epoch [4][300/391]	lr: 1.000e-03, eta: 17:48:20, time: 1.419, data_time: 0.002, memory: 1466, loss: 28.4393, loss_KD: 25.9485
2022-08-06 06:53:25,853 - mmcls - INFO - Epoch(val) [4][79]	accuracy_top-1: 35.6700, accuracy_top-5: 67.7700
2022-08-06 06:55:48,593 - mmcls - INFO - Epoch [5][100/391]	lr: 1.000e-03, eta: 17:32:40, time: 1.426, data_time: 0.021, memory: 1483, loss: 28.2432, loss_KD: 25.8763
2022-08-06 06:58:24,875 - mmcls - INFO - Epoch [5][200/391]	lr: 1.000e-03, eta: 18:24:33, time: 1.563, data_time: 0.002, memory: 1498, loss: 28.1692, loss_KD: 25.8396
2022-08-06 07:00:53,901 - mmcls - INFO - Epoch [5][300/391]	lr: 1.000e-03, eta: 19:05:38, time: 1.490, data_time: 0.002, memory: 1498, loss: 28.1163, loss_KD: 25.8245
2022-08-06 07:03:25,832 - mmcls - INFO - Epoch(val) [5][79]	accuracy_top-1: 39.8500, accuracy_top-5: 72.9300
2022-08-06 07:06:05,970 - mmcls - INFO - Epoch [6][100/391]	lr: 1.000e-03, eta: 18:55:21, time: 1.600, data_time: 0.021, memory: 1498, loss: 27.9066, loss_KD: 25.7445
2022-08-06 07:08:42,874 - mmcls - INFO - Epoch [6][200/391]	lr: 1.000e-03, eta: 19:33:33, time: 1.570, data_time: 0.002, memory: 1498, loss: 27.8600, loss_KD: 25.7288
2022-08-06 07:11:22,220 - mmcls - INFO - Epoch [6][300/391]	lr: 1.000e-03, eta: 20:09:29, time: 1.593, data_time: 0.002, memory: 1498, loss: 27.7994, loss_KD: 25.7024
2022-08-06 07:14:06,181 - mmcls - INFO - Epoch(val) [6][79]	accuracy_top-1: 42.7600, accuracy_top-5: 75.0800
2022-08-06 07:16:51,335 - mmcls - INFO - Epoch [7][100/391]	lr: 1.000e-03, eta: 19:57:25, time: 1.650, data_time: 0.021, memory: 1498, loss: 27.5481, loss_KD: 25.6101
2022-08-06 07:19:35,918 - mmcls - INFO - Epoch [7][200/391]	lr: 1.000e-03, eta: 20:30:23, time: 1.646, data_time: 0.002, memory: 1498, loss: 27.5979, loss_KD: 25.6267
2022-08-06 07:22:25,133 - mmcls - INFO - Epoch [7][300/391]	lr: 1.000e-03, eta: 21:02:51, time: 1.692, data_time: 0.002, memory: 1498, loss: 27.5249, loss_KD: 25.5953
2022-08-06 07:25:02,073 - mmcls - INFO - Epoch(val) [7][79]	accuracy_top-1: 43.2100, accuracy_top-5: 75.9500
2022-08-06 07:27:48,231 - mmcls - INFO - Epoch [8][100/391]	lr: 1.000e-03, eta: 20:48:20, time: 1.660, data_time: 0.021, memory: 1498, loss: 27.3663, loss_KD: 25.5477
2022-08-06 07:30:31,763 - mmcls - INFO - Epoch [8][200/391]	lr: 1.000e-03, eta: 21:14:05, time: 1.635, data_time: 0.002, memory: 1498, loss: 27.3254, loss_KD: 25.5226
2022-08-06 07:33:18,935 - mmcls - INFO - Epoch [8][300/391]	lr: 1.000e-03, eta: 21:39:27, time: 1.672, data_time: 0.002, memory: 1498, loss: 27.2573, loss_KD: 25.4912
2022-08-06 07:36:05,501 - mmcls - INFO - Epoch(val) [8][79]	accuracy_top-1: 49.6700, accuracy_top-5: 80.7100
2022-08-06 07:38:50,251 - mmcls - INFO - Epoch [9][100/391]	lr: 1.000e-03, eta: 21:23:11, time: 1.647, data_time: 0.021, memory: 1498, loss: 27.1064, loss_KD: 25.4451
2022-08-06 07:41:35,917 - mmcls - INFO - Epoch [9][200/391]	lr: 1.000e-03, eta: 21:45:04, time: 1.656, data_time: 0.002, memory: 1498, loss: 27.0516, loss_KD: 25.4021
2022-08-06 07:44:25,984 - mmcls - INFO - Epoch [9][300/391]	lr: 1.000e-03, eta: 22:07:07, time: 1.701, data_time: 0.002, memory: 1498, loss: 27.1226, loss_KD: 25.4549
2022-08-06 07:47:01,547 - mmcls - INFO - Epoch(val) [9][79]	accuracy_top-1: 50.3400, accuracy_top-5: 80.6000
2022-08-06 07:49:51,274 - mmcls - INFO - Epoch [10][100/391]	lr: 1.000e-03, eta: 21:52:08, time: 1.696, data_time: 0.022, memory: 1498, loss: 26.8952, loss_KD: 25.3533
2022-08-06 07:52:40,045 - mmcls - INFO - Epoch [10][200/391]	lr: 1.000e-03, eta: 22:11:27, time: 1.687, data_time: 0.002, memory: 1498, loss: 26.8911, loss_KD: 25.3549
2022-08-06 07:55:20,688 - mmcls - INFO - Epoch [10][300/391]	lr: 1.000e-03, eta: 22:27:00, time: 1.606, data_time: 0.002, memory: 1498, loss: 26.9078, loss_KD: 25.3538
2022-08-06 07:57:49,138 - mmcls - INFO - Saving checkpoint at 10 epochs
2022-08-06 07:57:56,507 - mmcls - INFO - Epoch(val) [10][79]	accuracy_top-1: 52.1600, accuracy_top-5: 81.7500
2022-08-06 08:00:38,681 - mmcls - INFO - Epoch [11][100/391]	lr: 1.000e-03, eta: 22:09:30, time: 1.620, data_time: 0.021, memory: 1498, loss: 26.7651, loss_KD: 25.3124
2022-08-06 08:03:23,001 - mmcls - INFO - Epoch [11][200/391]	lr: 1.000e-03, eta: 22:24:46, time: 1.643, data_time: 0.002, memory: 1498, loss: 26.7459, loss_KD: 25.3022
2022-08-06 08:06:04,236 - mmcls - INFO - Epoch [11][300/391]	lr: 1.000e-03, eta: 22:38:18, time: 1.613, data_time: 0.002, memory: 1498, loss: 26.7147, loss_KD: 25.2868
2022-08-06 08:08:39,878 - mmcls - INFO - Epoch(val) [11][79]	accuracy_top-1: 53.3300, accuracy_top-5: 82.7700
2022-08-06 08:11:20,817 - mmcls - INFO - Epoch [12][100/391]	lr: 1.000e-03, eta: 22:20:56, time: 1.608, data_time: 0.021, memory: 1498, loss: 26.5773, loss_KD: 25.2398
2022-08-06 08:14:07,192 - mmcls - INFO - Epoch [12][200/391]	lr: 1.000e-03, eta: 22:34:46, time: 1.664, data_time: 0.002, memory: 1498, loss: 26.5828, loss_KD: 25.2472
2022-08-06 08:16:41,466 - mmcls - INFO - Epoch [12][300/391]	lr: 1.000e-03, eta: 22:44:39, time: 1.543, data_time: 0.002, memory: 1498, loss: 26.6038, loss_KD: 25.2529
2022-08-06 08:19:14,639 - mmcls - INFO - Epoch(val) [12][79]	accuracy_top-1: 57.6200, accuracy_top-5: 84.9800
2022-08-06 08:21:57,959 - mmcls - INFO - Epoch [13][100/391]	lr: 1.000e-03, eta: 22:28:31, time: 1.632, data_time: 0.021, memory: 1498, loss: 26.4668, loss_KD: 25.2128
2022-08-06 08:24:32,667 - mmcls - INFO - Epoch [13][200/391]	lr: 1.000e-03, eta: 22:37:48, time: 1.548, data_time: 0.002, memory: 1498, loss: 26.4310, loss_KD: 25.1826
2022-08-06 08:27:12,953 - mmcls - INFO - Epoch [13][300/391]	lr: 1.000e-03, eta: 22:47:57, time: 1.602, data_time: 0.002, memory: 1498, loss: 26.4834, loss_KD: 25.2079
2022-08-06 08:29:42,938 - mmcls - INFO - Epoch(val) [13][79]	accuracy_top-1: 57.2900, accuracy_top-5: 85.4600
2022-08-06 08:32:20,616 - mmcls - INFO - Epoch [14][100/391]	lr: 1.000e-03, eta: 22:31:05, time: 1.575, data_time: 0.021, memory: 1498, loss: 26.3336, loss_KD: 25.1597
2022-08-06 08:34:54,092 - mmcls - INFO - Epoch [14][200/391]	lr: 1.000e-03, eta: 22:39:01, time: 1.535, data_time: 0.002, memory: 1498, loss: 26.3601, loss_KD: 25.1755
2022-08-06 08:37:41,126 - mmcls - INFO - Epoch [14][300/391]	lr: 1.000e-03, eta: 22:49:35, time: 1.670, data_time: 0.002, memory: 1498, loss: 26.3588, loss_KD: 25.1725
2022-08-06 08:40:12,057 - mmcls - INFO - Epoch(val) [14][79]	accuracy_top-1: 59.2300, accuracy_top-5: 86.3700
2022-08-06 08:42:43,577 - mmcls - INFO - Epoch [15][100/391]	lr: 1.000e-03, eta: 22:32:03, time: 1.514, data_time: 0.021, memory: 1498, loss: 26.2517, loss_KD: 25.1427
2022-08-06 08:45:27,544 - mmcls - INFO - Epoch [15][200/391]	lr: 1.000e-03, eta: 22:41:20, time: 1.640, data_time: 0.002, memory: 1498, loss: 26.2868, loss_KD: 25.1582
2022-08-06 08:48:02,560 - mmcls - INFO - Epoch [15][300/391]	lr: 1.000e-03, eta: 22:48:19, time: 1.551, data_time: 0.002, memory: 1498, loss: 26.2496, loss_KD: 25.1429
2022-08-06 08:50:41,208 - mmcls - INFO - Epoch(val) [15][79]	accuracy_top-1: 53.7200, accuracy_top-5: 82.5500
2022-08-06 08:53:15,013 - mmcls - INFO - Epoch [16][100/391]	lr: 1.000e-03, eta: 22:32:02, time: 1.537, data_time: 0.021, memory: 1498, loss: 26.1320, loss_KD: 25.1017
2022-08-06 08:55:55,112 - mmcls - INFO - Epoch [16][200/391]	lr: 1.000e-03, eta: 22:39:38, time: 1.600, data_time: 0.002, memory: 1498, loss: 26.1608, loss_KD: 25.1150
2022-08-06 08:58:37,328 - mmcls - INFO - Epoch [16][300/391]	lr: 1.000e-03, eta: 22:47:19, time: 1.622, data_time: 0.002, memory: 1498, loss: 26.2198, loss_KD: 25.1524
2022-08-06 09:01:08,035 - mmcls - INFO - Epoch(val) [16][79]	accuracy_top-1: 59.1700, accuracy_top-5: 85.8600
2022-08-06 09:03:51,129 - mmcls - INFO - Epoch [17][100/391]	lr: 1.000e-03, eta: 22:33:24, time: 1.629, data_time: 0.021, memory: 1498, loss: 26.0586, loss_KD: 25.0844
2022-08-06 09:06:28,477 - mmcls - INFO - Epoch [17][200/391]	lr: 1.000e-03, eta: 22:39:43, time: 1.573, data_time: 0.002, memory: 1498, loss: 26.1329, loss_KD: 25.1170
2022-08-06 09:09:03,874 - mmcls - INFO - Epoch [17][300/391]	lr: 1.000e-03, eta: 22:45:25, time: 1.554, data_time: 0.002, memory: 1498, loss: 26.1369, loss_KD: 25.1288
2022-08-06 09:11:33,101 - mmcls - INFO - Epoch(val) [17][79]	accuracy_top-1: 59.8800, accuracy_top-5: 86.7500
2022-08-06 09:14:12,648 - mmcls - INFO - Epoch [18][100/391]	lr: 1.000e-03, eta: 22:31:22, time: 1.594, data_time: 0.021, memory: 1498, loss: 26.0339, loss_KD: 25.0940
2022-08-06 09:16:55,191 - mmcls - INFO - Epoch [18][200/391]	lr: 1.000e-03, eta: 22:38:00, time: 1.625, data_time: 0.002, memory: 1498, loss: 26.0564, loss_KD: 25.1131
2022-08-06 09:19:31,958 - mmcls - INFO - Epoch [18][300/391]	lr: 1.000e-03, eta: 22:43:22, time: 1.567, data_time: 0.002, memory: 1498, loss: 26.0208, loss_KD: 25.0892
2022-08-06 09:22:01,896 - mmcls - INFO - Epoch(val) [18][79]	accuracy_top-1: 62.5100, accuracy_top-5: 87.9400
2022-08-06 09:24:38,760 - mmcls - INFO - Epoch [19][100/391]	lr: 1.000e-03, eta: 22:29:20, time: 1.567, data_time: 0.021, memory: 1498, loss: 25.9359, loss_KD: 25.0671
2022-08-06 09:27:20,209 - mmcls - INFO - Epoch [19][200/391]	lr: 1.000e-03, eta: 22:35:12, time: 1.614, data_time: 0.002, memory: 1498, loss: 25.9816, loss_KD: 25.0884
2022-08-06 09:29:59,927 - mmcls - INFO - Epoch [19][300/391]	lr: 1.000e-03, eta: 22:40:33, time: 1.597, data_time: 0.002, memory: 1498, loss: 25.9829, loss_KD: 25.0895
2022-08-06 09:32:32,933 - mmcls - INFO - Epoch(val) [19][79]	accuracy_top-1: 62.3400, accuracy_top-5: 88.1000
2022-08-06 09:35:09,488 - mmcls - INFO - Epoch [20][100/391]	lr: 1.000e-03, eta: 22:26:56, time: 1.565, data_time: 0.021, memory: 1498, loss: 25.9143, loss_KD: 25.0863
2022-08-06 09:37:46,998 - mmcls - INFO - Epoch [20][200/391]	lr: 1.000e-03, eta: 22:31:41, time: 1.575, data_time: 0.002, memory: 1498, loss: 25.9087, loss_KD: 25.0792
2022-08-06 09:40:29,794 - mmcls - INFO - Epoch [20][300/391]	lr: 1.000e-03, eta: 22:37:02, time: 1.627, data_time: 0.002, memory: 1498, loss: 25.9777, loss_KD: 25.1115
2022-08-06 09:42:53,075 - mmcls - INFO - Saving checkpoint at 20 epochs
2022-08-06 09:43:02,178 - mmcls - INFO - Epoch(val) [20][79]	accuracy_top-1: 62.1200, accuracy_top-5: 88.2000
2022-08-06 09:45:48,360 - mmcls - INFO - Epoch [21][100/391]	lr: 1.000e-03, eta: 22:25:16, time: 1.660, data_time: 0.021, memory: 1498, loss: 25.8969, loss_KD: 25.0979
2022-08-06 09:48:31,433 - mmcls - INFO - Epoch [21][200/391]	lr: 1.000e-03, eta: 22:30:24, time: 1.631, data_time: 0.002, memory: 1498, loss: 25.8973, loss_KD: 25.0868
2022-08-06 09:51:12,728 - mmcls - INFO - Epoch [21][300/391]	lr: 1.000e-03, eta: 22:35:04, time: 1.613, data_time: 0.002, memory: 1498, loss: 25.8853, loss_KD: 25.0851
2022-08-06 09:53:42,669 - mmcls - INFO - Epoch(val) [21][79]	accuracy_top-1: 63.4900, accuracy_top-5: 88.3700
2022-08-06 09:56:23,167 - mmcls - INFO - Epoch [22][100/391]	lr: 1.000e-03, eta: 22:22:48, time: 1.604, data_time: 0.021, memory: 1498, loss: 25.8354, loss_KD: 25.0950
2022-08-06 09:59:04,287 - mmcls - INFO - Epoch [22][200/391]	lr: 1.000e-03, eta: 22:27:13, time: 1.611, data_time: 0.002, memory: 1498, loss: 25.8191, loss_KD: 25.0704
2022-08-06 10:01:43,508 - mmcls - INFO - Epoch [22][300/391]	lr: 1.000e-03, eta: 22:31:12, time: 1.592, data_time: 0.002, memory: 1498, loss: 25.8819, loss_KD: 25.1060
2022-08-06 10:04:16,469 - mmcls - INFO - Epoch(val) [22][79]	accuracy_top-1: 64.5600, accuracy_top-5: 89.2000
2022-08-06 10:07:01,126 - mmcls - INFO - Epoch [23][100/391]	lr: 1.000e-03, eta: 22:19:49, time: 1.645, data_time: 0.021, memory: 1498, loss: 25.7646, loss_KD: 25.0748
2022-08-06 10:09:41,618 - mmcls - INFO - Epoch [23][200/391]	lr: 1.000e-03, eta: 22:23:47, time: 1.605, data_time: 0.002, memory: 1498, loss: 25.7864, loss_KD: 25.0805
2022-08-06 10:12:24,539 - mmcls - INFO - Epoch [23][300/391]	lr: 1.000e-03, eta: 22:27:55, time: 1.630, data_time: 0.002, memory: 1498, loss: 25.8241, loss_KD: 25.1024
2022-08-06 10:14:53,856 - mmcls - INFO - Epoch(val) [23][79]	accuracy_top-1: 64.0300, accuracy_top-5: 88.4200
2022-08-06 10:17:39,507 - mmcls - INFO - Epoch [24][100/391]	lr: 1.000e-03, eta: 22:16:56, time: 1.656, data_time: 0.023, memory: 1498, loss: 25.7415, loss_KD: 25.0864
2022-08-06 10:20:15,650 - mmcls - INFO - Epoch [24][200/391]	lr: 1.000e-03, eta: 22:20:01, time: 1.561, data_time: 0.002, memory: 1498, loss: 25.7950, loss_KD: 25.1096
2022-08-06 10:22:53,793 - mmcls - INFO - Epoch [24][300/391]	lr: 1.000e-03, eta: 22:23:13, time: 1.581, data_time: 0.002, memory: 1498, loss: 25.8061, loss_KD: 25.1081
2022-08-06 10:25:35,722 - mmcls - INFO - Epoch(val) [24][79]	accuracy_top-1: 62.5100, accuracy_top-5: 88.1000
2022-08-06 10:28:13,399 - mmcls - INFO - Epoch [25][100/391]	lr: 1.000e-03, eta: 22:11:32, time: 1.575, data_time: 0.021, memory: 1498, loss: 25.6758, loss_KD: 25.0732
2022-08-06 10:30:55,893 - mmcls - INFO - Epoch [25][200/391]	lr: 1.000e-03, eta: 22:15:07, time: 1.625, data_time: 0.002, memory: 1498, loss: 25.7290, loss_KD: 25.0923
2022-08-06 10:33:39,691 - mmcls - INFO - Epoch [25][300/391]	lr: 1.000e-03, eta: 22:18:43, time: 1.638, data_time: 0.002, memory: 1498, loss: 25.7723, loss_KD: 25.1254
2022-08-06 10:36:12,196 - mmcls - INFO - Epoch(val) [25][79]	accuracy_top-1: 64.2400, accuracy_top-5: 88.6500
2022-08-06 10:38:50,580 - mmcls - INFO - Epoch [26][100/391]	lr: 1.000e-03, eta: 22:07:25, time: 1.582, data_time: 0.021, memory: 1498, loss: 25.7066, loss_KD: 25.1109
2022-08-06 10:41:30,146 - mmcls - INFO - Epoch [26][200/391]	lr: 1.000e-03, eta: 22:10:23, time: 1.596, data_time: 0.002, memory: 1498, loss: 25.6977, loss_KD: 25.1075
2022-08-06 10:44:14,362 - mmcls - INFO - Epoch [26][300/391]	lr: 1.000e-03, eta: 22:13:45, time: 1.642, data_time: 0.002, memory: 1498, loss: 25.7628, loss_KD: 25.1355
2022-08-06 10:46:48,315 - mmcls - INFO - Epoch(val) [26][79]	accuracy_top-1: 64.9700, accuracy_top-5: 89.2500
2022-08-06 10:49:25,745 - mmcls - INFO - Epoch [27][100/391]	lr: 1.000e-03, eta: 22:02:37, time: 1.573, data_time: 0.021, memory: 1498, loss: 25.6548, loss_KD: 25.1088
2022-08-06 10:52:03,981 - mmcls - INFO - Epoch [27][200/391]	lr: 1.000e-03, eta: 22:05:10, time: 1.582, data_time: 0.002, memory: 1498, loss: 25.7085, loss_KD: 25.1311
2022-08-06 10:54:49,653 - mmcls - INFO - Epoch [27][300/391]	lr: 1.000e-03, eta: 22:08:27, time: 1.657, data_time: 0.003, memory: 1498, loss: 25.7300, loss_KD: 25.1397
2022-08-06 10:57:22,229 - mmcls - INFO - Epoch(val) [27][79]	accuracy_top-1: 65.5600, accuracy_top-5: 89.3500
2022-08-06 11:00:01,898 - mmcls - INFO - Epoch [28][100/391]	lr: 1.000e-03, eta: 21:57:49, time: 1.595, data_time: 0.021, memory: 1498, loss: 25.6214, loss_KD: 25.1089
2022-08-06 11:02:45,336 - mmcls - INFO - Epoch [28][200/391]	lr: 1.000e-03, eta: 22:00:43, time: 1.635, data_time: 0.002, memory: 1498, loss: 25.6816, loss_KD: 25.1351
2022-08-06 11:05:23,265 - mmcls - INFO - Epoch [28][300/391]	lr: 1.000e-03, eta: 22:02:56, time: 1.579, data_time: 0.002, memory: 1498, loss: 25.6982, loss_KD: 25.1448
2022-08-06 11:07:58,623 - mmcls - INFO - Epoch(val) [28][79]	accuracy_top-1: 66.0300, accuracy_top-5: 89.2600
2022-08-06 11:10:33,472 - mmcls - INFO - Epoch [29][100/391]	lr: 1.000e-03, eta: 21:52:03, time: 1.547, data_time: 0.021, memory: 1498, loss: 25.6149, loss_KD: 25.1258
2022-08-06 11:13:12,399 - mmcls - INFO - Epoch [29][200/391]	lr: 1.000e-03, eta: 21:54:16, time: 1.589, data_time: 0.002, memory: 1498, loss: 25.6494, loss_KD: 25.1409
2022-08-06 11:15:53,039 - mmcls - INFO - Epoch [29][300/391]	lr: 1.000e-03, eta: 21:56:35, time: 1.607, data_time: 0.002, memory: 1498, loss: 25.6604, loss_KD: 25.1499
2022-08-06 11:18:32,420 - mmcls - INFO - Epoch(val) [29][79]	accuracy_top-1: 65.0900, accuracy_top-5: 88.9300
2022-08-06 11:21:15,689 - mmcls - INFO - Epoch [30][100/391]	lr: 1.000e-03, eta: 21:46:47, time: 1.632, data_time: 0.021, memory: 1498, loss: 25.5818, loss_KD: 25.1284
2022-08-06 11:23:57,635 - mmcls - INFO - Epoch [30][200/391]	lr: 1.000e-03, eta: 21:49:06, time: 1.619, data_time: 0.002, memory: 1498, loss: 25.6085, loss_KD: 25.1375
2022-08-06 11:26:40,059 - mmcls - INFO - Epoch [30][300/391]	lr: 1.000e-03, eta: 21:51:23, time: 1.624, data_time: 0.002, memory: 1498, loss: 25.6770, loss_KD: 25.1761
2022-08-06 11:29:08,346 - mmcls - INFO - Saving checkpoint at 30 epochs
2022-08-06 11:29:15,207 - mmcls - INFO - Epoch(val) [30][79]	accuracy_top-1: 65.5800, accuracy_top-5: 89.5500
2022-08-06 11:31:51,379 - mmcls - INFO - Epoch [31][100/391]	lr: 1.000e-03, eta: 21:41:06, time: 1.561, data_time: 0.022, memory: 1498, loss: 25.5829, loss_KD: 25.1511
2022-08-06 11:34:37,162 - mmcls - INFO - Epoch [31][200/391]	lr: 1.000e-03, eta: 21:43:36, time: 1.657, data_time: 0.002, memory: 1498, loss: 25.5984, loss_KD: 25.1628
2022-08-06 11:37:16,761 - mmcls - INFO - Epoch [31][300/391]	lr: 1.000e-03, eta: 21:45:27, time: 1.596, data_time: 0.002, memory: 1498, loss: 25.6317, loss_KD: 25.1769
2022-08-06 11:39:49,050 - mmcls - INFO - Epoch(val) [31][79]	accuracy_top-1: 67.2200, accuracy_top-5: 90.4700
2022-08-06 11:42:33,708 - mmcls - INFO - Epoch [32][100/391]	lr: 1.000e-03, eta: 21:36:08, time: 1.645, data_time: 0.023, memory: 1498, loss: 25.5437, loss_KD: 25.1501
2022-08-06 11:45:15,731 - mmcls - INFO - Epoch [32][200/391]	lr: 1.000e-03, eta: 21:38:06, time: 1.620, data_time: 0.002, memory: 1498, loss: 25.6013, loss_KD: 25.1718
2022-08-06 11:47:57,878 - mmcls - INFO - Epoch [32][300/391]	lr: 1.000e-03, eta: 21:40:01, time: 1.622, data_time: 0.002, memory: 1498, loss: 25.6659, loss_KD: 25.2148
2022-08-06 11:50:35,513 - mmcls - INFO - Epoch(val) [32][79]	accuracy_top-1: 63.9900, accuracy_top-5: 88.9200
2022-08-06 11:53:13,041 - mmcls - INFO - Epoch [33][100/391]	lr: 1.000e-03, eta: 21:30:15, time: 1.574, data_time: 0.021, memory: 1498, loss: 25.5487, loss_KD: 25.1726
2022-08-06 11:55:54,925 - mmcls - INFO - Epoch [33][200/391]	lr: 1.000e-03, eta: 21:32:03, time: 1.618, data_time: 0.002, memory: 1498, loss: 25.5748, loss_KD: 25.1770
2022-08-06 11:58:44,157 - mmcls - INFO - Epoch [33][300/391]	lr: 1.000e-03, eta: 21:34:24, time: 1.693, data_time: 0.003, memory: 1498, loss: 25.6412, loss_KD: 25.2172
2022-08-06 12:01:17,832 - mmcls - INFO - Epoch(val) [33][79]	accuracy_top-1: 67.2000, accuracy_top-5: 90.1800
2022-08-06 12:03:57,415 - mmcls - INFO - Epoch [34][100/391]	lr: 1.000e-03, eta: 21:24:59, time: 1.595, data_time: 0.021, memory: 1498, loss: 25.5383, loss_KD: 25.1874
2022-08-06 12:06:44,949 - mmcls - INFO - Epoch [34][200/391]	lr: 1.000e-03, eta: 21:27:06, time: 1.675, data_time: 0.002, memory: 1498, loss: 25.5965, loss_KD: 25.2134
2022-08-06 12:09:27,115 - mmcls - INFO - Epoch [34][300/391]	lr: 1.000e-03, eta: 21:28:42, time: 1.622, data_time: 0.002, memory: 1498, loss: 25.5827, loss_KD: 25.2026
2022-08-06 12:12:00,986 - mmcls - INFO - Epoch(val) [34][79]	accuracy_top-1: 67.7900, accuracy_top-5: 90.1200
2022-08-06 12:14:41,426 - mmcls - INFO - Epoch [35][100/391]	lr: 1.000e-03, eta: 21:19:31, time: 1.603, data_time: 0.023, memory: 1498, loss: 25.5743, loss_KD: 25.2278
2022-08-06 12:17:24,327 - mmcls - INFO - Epoch [35][200/391]	lr: 1.000e-03, eta: 21:21:05, time: 1.628, data_time: 0.002, memory: 1498, loss: 25.5582, loss_KD: 25.2088
2022-08-06 12:20:09,818 - mmcls - INFO - Epoch [35][300/391]	lr: 1.000e-03, eta: 21:22:48, time: 1.655, data_time: 0.003, memory: 1498, loss: 25.6075, loss_KD: 25.2433
2022-08-06 12:22:44,190 - mmcls - INFO - Epoch(val) [35][79]	accuracy_top-1: 67.2600, accuracy_top-5: 90.1500
2022-08-06 12:25:27,035 - mmcls - INFO - Epoch [36][100/391]	lr: 1.000e-03, eta: 21:13:58, time: 1.627, data_time: 0.022, memory: 1498, loss: 25.5395, loss_KD: 25.2221
2022-08-06 12:28:14,555 - mmcls - INFO - Epoch [36][200/391]	lr: 1.000e-03, eta: 21:15:45, time: 1.675, data_time: 0.002, memory: 1498, loss: 25.5793, loss_KD: 25.2441
2022-08-06 12:30:53,167 - mmcls - INFO - Epoch [36][300/391]	lr: 1.000e-03, eta: 21:16:48, time: 1.586, data_time: 0.002, memory: 1498, loss: 25.6153, loss_KD: 25.2644
2022-08-06 12:33:29,219 - mmcls - INFO - Epoch(val) [36][79]	accuracy_top-1: 68.2100, accuracy_top-5: 90.3200
2022-08-06 12:36:12,800 - mmcls - INFO - Epoch [37][100/391]	lr: 1.000e-03, eta: 21:08:09, time: 1.635, data_time: 0.021, memory: 1498, loss: 25.5374, loss_KD: 25.2440
2022-08-06 12:38:57,596 - mmcls - INFO - Epoch [37][200/391]	lr: 1.000e-03, eta: 21:09:36, time: 1.647, data_time: 0.002, memory: 1498, loss: 25.5450, loss_KD: 25.2388
2022-08-06 12:41:48,485 - mmcls - INFO - Epoch [37][300/391]	lr: 1.000e-03, eta: 21:11:27, time: 1.709, data_time: 0.003, memory: 1498, loss: 25.6270, loss_KD: 25.2914
2022-08-06 12:44:31,988 - mmcls - INFO - Epoch(val) [37][79]	accuracy_top-1: 67.7400, accuracy_top-5: 90.4900
2022-08-06 12:47:15,415 - mmcls - INFO - Epoch [38][100/391]	lr: 1.000e-03, eta: 21:02:54, time: 1.633, data_time: 0.021, memory: 1498, loss: 25.5707, loss_KD: 25.2785
2022-08-06 12:49:59,055 - mmcls - INFO - Epoch [38][200/391]	lr: 1.000e-03, eta: 21:04:08, time: 1.636, data_time: 0.002, memory: 1498, loss: 25.5823, loss_KD: 25.2804
2022-08-06 12:52:52,825 - mmcls - INFO - Epoch [38][300/391]	lr: 1.000e-03, eta: 21:06:03, time: 1.738, data_time: 0.003, memory: 1498, loss: 25.5839, loss_KD: 25.2869
2022-08-06 12:55:25,207 - mmcls - INFO - Epoch(val) [38][79]	accuracy_top-1: 68.3000, accuracy_top-5: 90.4800
2022-08-06 12:58:06,815 - mmcls - INFO - Epoch [39][100/391]	lr: 1.000e-03, eta: 20:57:29, time: 1.614, data_time: 0.023, memory: 1498, loss: 25.5615, loss_KD: 25.2940
2022-08-06 13:00:51,199 - mmcls - INFO - Epoch [39][200/391]	lr: 1.000e-03, eta: 20:58:39, time: 1.644, data_time: 0.002, memory: 1498, loss: 25.5898, loss_KD: 25.3074
2022-08-06 13:03:31,674 - mmcls - INFO - Epoch [39][300/391]	lr: 1.000e-03, eta: 20:59:29, time: 1.604, data_time: 0.002, memory: 1498, loss: 25.5972, loss_KD: 25.3092
2022-08-06 13:06:09,317 - mmcls - INFO - Epoch(val) [39][79]	accuracy_top-1: 68.1600, accuracy_top-5: 90.7400
2022-08-06 13:08:48,997 - mmcls - INFO - Epoch [40][100/391]	lr: 1.000e-03, eta: 20:50:56, time: 1.596, data_time: 0.021, memory: 1498, loss: 25.5444, loss_KD: 25.2963
2022-08-06 13:11:35,938 - mmcls - INFO - Epoch [40][200/391]	lr: 1.000e-03, eta: 20:52:10, time: 1.669, data_time: 0.002, memory: 1498, loss: 25.5672, loss_KD: 25.3077
2022-08-06 13:14:23,879 - mmcls - INFO - Epoch [40][300/391]	lr: 1.000e-03, eta: 20:53:24, time: 1.679, data_time: 0.003, memory: 1498, loss: 25.5985, loss_KD: 25.3274
2022-08-06 13:16:51,332 - mmcls - INFO - Saving checkpoint at 40 epochs
2022-08-06 13:16:58,226 - mmcls - INFO - Epoch(val) [40][79]	accuracy_top-1: 68.7300, accuracy_top-5: 90.9100
2022-08-06 13:19:42,258 - mmcls - INFO - Epoch [41][100/391]	lr: 1.000e-03, eta: 20:45:15, time: 1.639, data_time: 0.021, memory: 1498, loss: 25.5692, loss_KD: 25.3346
2022-08-06 13:22:26,566 - mmcls - INFO - Epoch [41][200/391]	lr: 1.000e-03, eta: 20:46:12, time: 1.644, data_time: 0.002, memory: 1498, loss: 25.5728, loss_KD: 25.3279
2022-08-06 13:25:09,095 - mmcls - INFO - Epoch [41][300/391]	lr: 1.000e-03, eta: 20:46:59, time: 1.625, data_time: 0.002, memory: 1498, loss: 25.5908, loss_KD: 25.3355
2022-08-06 13:27:56,257 - mmcls - INFO - Epoch(val) [41][79]	accuracy_top-1: 68.3300, accuracy_top-5: 90.5900
2022-08-06 13:30:42,175 - mmcls - INFO - Epoch [42][100/391]	lr: 1.000e-03, eta: 20:39:04, time: 1.658, data_time: 0.021, memory: 1498, loss: 25.5654, loss_KD: 25.3447
2022-08-06 13:33:22,163 - mmcls - INFO - Epoch [42][200/391]	lr: 1.000e-03, eta: 20:39:38, time: 1.600, data_time: 0.002, memory: 1498, loss: 25.5784, loss_KD: 25.3495
2022-08-06 13:36:06,621 - mmcls - INFO - Epoch [42][300/391]	lr: 1.000e-03, eta: 20:40:26, time: 1.645, data_time: 0.002, memory: 1498, loss: 25.6105, loss_KD: 25.3678
2022-08-06 13:38:51,924 - mmcls - INFO - Epoch(val) [42][79]	accuracy_top-1: 68.9400, accuracy_top-5: 90.5400
2022-08-06 13:41:35,163 - mmcls - INFO - Epoch [43][100/391]	lr: 1.000e-03, eta: 20:32:27, time: 1.631, data_time: 0.023, memory: 1498, loss: 25.5600, loss_KD: 25.3567
2022-08-06 13:44:20,571 - mmcls - INFO - Epoch [43][200/391]	lr: 1.000e-03, eta: 20:33:16, time: 1.654, data_time: 0.002, memory: 1498, loss: 25.5994, loss_KD: 25.3753
2022-08-06 13:47:03,730 - mmcls - INFO - Epoch [43][300/391]	lr: 1.000e-03, eta: 20:33:54, time: 1.632, data_time: 0.002, memory: 1498, loss: 25.6163, loss_KD: 25.3863
2022-08-06 13:49:43,032 - mmcls - INFO - Epoch(val) [43][79]	accuracy_top-1: 68.0600, accuracy_top-5: 90.2200
2022-08-06 13:52:24,810 - mmcls - INFO - Epoch [44][100/391]	lr: 1.000e-03, eta: 20:25:56, time: 1.616, data_time: 0.023, memory: 1498, loss: 25.5733, loss_KD: 25.3722
2022-08-06 13:55:06,656 - mmcls - INFO - Epoch [44][200/391]	lr: 1.000e-03, eta: 20:26:26, time: 1.618, data_time: 0.003, memory: 1498, loss: 25.5956, loss_KD: 25.3915
2022-08-06 13:57:54,412 - mmcls - INFO - Epoch [44][300/391]	lr: 1.000e-03, eta: 20:27:16, time: 1.678, data_time: 0.003, memory: 1498, loss: 25.6242, loss_KD: 25.4084
2022-08-06 14:00:34,612 - mmcls - INFO - Epoch(val) [44][79]	accuracy_top-1: 69.3400, accuracy_top-5: 90.8300
2022-08-06 14:03:20,119 - mmcls - INFO - Epoch [45][100/391]	lr: 1.000e-03, eta: 20:19:37, time: 1.654, data_time: 0.022, memory: 1498, loss: 25.5742, loss_KD: 25.3940
2022-08-06 14:05:58,048 - mmcls - INFO - Epoch [45][200/391]	lr: 1.000e-03, eta: 20:19:49, time: 1.580, data_time: 0.002, memory: 1498, loss: 25.5955, loss_KD: 25.4104
2022-08-06 14:08:45,797 - mmcls - INFO - Epoch [45][300/391]	lr: 1.000e-03, eta: 20:20:33, time: 1.677, data_time: 0.002, memory: 1498, loss: 25.6176, loss_KD: 25.4232
2022-08-06 14:11:26,690 - mmcls - INFO - Epoch(val) [45][79]	accuracy_top-1: 69.2800, accuracy_top-5: 90.6900
2022-08-06 14:14:14,803 - mmcls - INFO - Epoch [46][100/391]	lr: 1.000e-03, eta: 20:13:09, time: 1.680, data_time: 0.021, memory: 1498, loss: 25.5991, loss_KD: 25.4203
2022-08-06 14:17:00,564 - mmcls - INFO - Epoch [46][200/391]	lr: 1.000e-03, eta: 20:13:43, time: 1.657, data_time: 0.002, memory: 1498, loss: 25.5919, loss_KD: 25.4159
2022-08-06 14:19:33,948 - mmcls - INFO - Epoch [46][300/391]	lr: 1.000e-03, eta: 20:13:33, time: 1.534, data_time: 0.002, memory: 1498, loss: 25.6299, loss_KD: 25.4426
2022-08-06 14:21:48,348 - mmcls - INFO - Epoch(val) [46][79]	accuracy_top-1: 69.2600, accuracy_top-5: 90.9900
2022-08-06 14:24:13,256 - mmcls - INFO - Epoch [47][100/391]	lr: 1.000e-03, eta: 20:04:57, time: 1.448, data_time: 0.021, memory: 1498, loss: 25.5739, loss_KD: 25.4156
2022-08-06 14:26:31,889 - mmcls - INFO - Epoch [47][200/391]	lr: 1.000e-03, eta: 20:03:57, time: 1.386, data_time: 0.002, memory: 1498, loss: 25.6219, loss_KD: 25.4511
2022-08-06 14:29:00,459 - mmcls - INFO - Epoch [47][300/391]	lr: 1.000e-03, eta: 20:03:29, time: 1.486, data_time: 0.002, memory: 1498, loss: 25.6726, loss_KD: 25.4862
2022-08-06 14:31:18,867 - mmcls - INFO - Epoch(val) [47][79]	accuracy_top-1: 69.0800, accuracy_top-5: 90.3000
2022-08-06 14:33:43,746 - mmcls - INFO - Epoch [48][100/391]	lr: 1.000e-03, eta: 19:55:03, time: 1.447, data_time: 0.021, memory: 1498, loss: 25.6310, loss_KD: 25.4662
2022-08-06 14:36:11,280 - mmcls - INFO - Epoch [48][200/391]	lr: 1.000e-03, eta: 19:54:31, time: 1.475, data_time: 0.002, memory: 1498, loss: 25.6474, loss_KD: 25.4811
2022-08-06 14:38:36,167 - mmcls - INFO - Epoch [48][300/391]	lr: 1.000e-03, eta: 19:53:49, time: 1.449, data_time: 0.002, memory: 1498, loss: 25.6428, loss_KD: 25.4750
2022-08-06 14:40:52,032 - mmcls - INFO - Epoch(val) [48][79]	accuracy_top-1: 69.3200, accuracy_top-5: 90.8500
2022-08-06 14:43:16,948 - mmcls - INFO - Epoch [49][100/391]	lr: 1.000e-03, eta: 19:45:32, time: 1.448, data_time: 0.021, memory: 1498, loss: 25.6163, loss_KD: 25.4764
2022-08-06 14:45:39,686 - mmcls - INFO - Epoch [49][200/391]	lr: 1.000e-03, eta: 19:44:43, time: 1.427, data_time: 0.002, memory: 1498, loss: 25.6380, loss_KD: 25.4904
2022-08-06 14:48:09,525 - mmcls - INFO - Epoch [49][300/391]	lr: 1.000e-03, eta: 19:44:16, time: 1.499, data_time: 0.002, memory: 1498, loss: 25.6670, loss_KD: 25.5064
2022-08-06 14:50:42,381 - mmcls - INFO - Epoch(val) [49][79]	accuracy_top-1: 68.7300, accuracy_top-5: 90.5200
2022-08-06 14:53:34,019 - mmcls - INFO - Epoch [50][100/391]	lr: 1.000e-03, eta: 19:37:29, time: 1.715, data_time: 0.021, memory: 1498, loss: 25.6413, loss_KD: 25.5040
2022-08-06 14:56:16,394 - mmcls - INFO - Epoch [50][200/391]	lr: 1.000e-03, eta: 19:37:38, time: 1.623, data_time: 0.002, memory: 1498, loss: 25.6454, loss_KD: 25.5068
2022-08-06 14:59:06,413 - mmcls - INFO - Epoch [50][300/391]	lr: 1.000e-03, eta: 19:38:09, time: 1.700, data_time: 0.003, memory: 1498, loss: 25.6800, loss_KD: 25.5294
2022-08-06 15:01:44,347 - mmcls - INFO - Saving checkpoint at 50 epochs
2022-08-06 15:01:54,335 - mmcls - INFO - Epoch(val) [50][79]	accuracy_top-1: 70.0800, accuracy_top-5: 91.4800
2022-08-06 15:04:46,700 - mmcls - INFO - Epoch [51][100/391]	lr: 1.000e-03, eta: 19:31:27, time: 1.723, data_time: 0.022, memory: 1498, loss: 25.6499, loss_KD: 25.5213
2022-08-06 15:07:49,188 - mmcls - INFO - Epoch [51][200/391]	lr: 1.000e-03, eta: 19:32:32, time: 1.825, data_time: 0.002, memory: 1498, loss: 25.6729, loss_KD: 25.5336
2022-08-06 15:10:51,570 - mmcls - INFO - Epoch [51][300/391]	lr: 1.000e-03, eta: 19:33:34, time: 1.823, data_time: 0.002, memory: 1498, loss: 25.6962, loss_KD: 25.5471
2022-08-06 15:13:40,756 - mmcls - INFO - Epoch(val) [51][79]	accuracy_top-1: 70.1700, accuracy_top-5: 90.8800
2022-08-06 15:16:40,283 - mmcls - INFO - Epoch [52][100/391]	lr: 1.000e-03, eta: 19:27:15, time: 1.794, data_time: 0.024, memory: 1498, loss: 25.6655, loss_KD: 25.5412
2022-08-06 15:19:39,897 - mmcls - INFO - Epoch [52][200/391]	lr: 1.000e-03, eta: 19:28:05, time: 1.796, data_time: 0.002, memory: 1498, loss: 25.6752, loss_KD: 25.5471
2022-08-06 15:22:27,660 - mmcls - INFO - Epoch [52][300/391]	lr: 1.000e-03, eta: 19:28:19, time: 1.677, data_time: 0.002, memory: 1498, loss: 25.6909, loss_KD: 25.5567
2022-08-06 15:24:48,956 - mmcls - INFO - Epoch(val) [52][79]	accuracy_top-1: 70.8900, accuracy_top-5: 91.1800
2022-08-06 15:27:09,528 - mmcls - INFO - Epoch [53][100/391]	lr: 1.000e-03, eta: 19:20:12, time: 1.404, data_time: 0.021, memory: 1498, loss: 25.6878, loss_KD: 25.5684
2022-08-06 15:29:33,975 - mmcls - INFO - Epoch [53][200/391]	lr: 1.000e-03, eta: 19:19:19, time: 1.444, data_time: 0.002, memory: 1498, loss: 25.6883, loss_KD: 25.5674
2022-08-06 15:31:58,986 - mmcls - INFO - Epoch [53][300/391]	lr: 1.000e-03, eta: 19:18:26, time: 1.450, data_time: 0.002, memory: 1498, loss: 25.6967, loss_KD: 25.5682
2022-08-06 15:34:20,610 - mmcls - INFO - Epoch(val) [53][79]	accuracy_top-1: 70.2800, accuracy_top-5: 91.2400
2022-08-06 15:36:39,766 - mmcls - INFO - Epoch [54][100/391]	lr: 1.000e-03, eta: 19:10:23, time: 1.390, data_time: 0.021, memory: 1498, loss: 25.6947, loss_KD: 25.5787
2022-08-06 15:39:03,207 - mmcls - INFO - Epoch [54][200/391]	lr: 1.000e-03, eta: 19:09:26, time: 1.434, data_time: 0.002, memory: 1498, loss: 25.7201, loss_KD: 25.5963
2022-08-06 15:41:24,402 - mmcls - INFO - Epoch [54][300/391]	lr: 1.000e-03, eta: 19:08:22, time: 1.412, data_time: 0.002, memory: 1498, loss: 25.7366, loss_KD: 25.6084
2022-08-06 15:43:38,588 - mmcls - INFO - Epoch(val) [54][79]	accuracy_top-1: 70.8000, accuracy_top-5: 91.3800
2022-08-06 15:46:00,696 - mmcls - INFO - Epoch [55][100/391]	lr: 1.000e-03, eta: 19:00:35, time: 1.420, data_time: 0.021, memory: 1498, loss: 25.7074, loss_KD: 25.6012
2022-08-06 15:48:27,904 - mmcls - INFO - Epoch [55][200/391]	lr: 1.000e-03, eta: 18:59:48, time: 1.472, data_time: 0.002, memory: 1498, loss: 25.7150, loss_KD: 25.6040
2022-08-06 15:51:08,961 - mmcls - INFO - Epoch [55][300/391]	lr: 1.000e-03, eta: 18:59:36, time: 1.611, data_time: 0.002, memory: 1498, loss: 25.7445, loss_KD: 25.6202
2022-08-06 15:53:44,116 - mmcls - INFO - Epoch(val) [55][79]	accuracy_top-1: 70.0300, accuracy_top-5: 91.2000
2022-08-06 15:56:35,629 - mmcls - INFO - Epoch [56][100/391]	lr: 1.000e-03, eta: 18:53:12, time: 1.713, data_time: 0.024, memory: 1498, loss: 25.7342, loss_KD: 25.6295
2022-08-06 15:59:34,777 - mmcls - INFO - Epoch [56][200/391]	lr: 1.000e-03, eta: 18:53:46, time: 1.792, data_time: 0.003, memory: 1498, loss: 25.7467, loss_KD: 25.6334
2022-08-06 16:02:40,367 - mmcls - INFO - Epoch [56][300/391]	lr: 1.000e-03, eta: 18:54:34, time: 1.856, data_time: 0.002, memory: 1498, loss: 25.7543, loss_KD: 25.6390
2022-08-06 16:05:31,784 - mmcls - INFO - Epoch(val) [56][79]	accuracy_top-1: 70.6000, accuracy_top-5: 91.4500
2022-08-06 16:08:27,595 - mmcls - INFO - Epoch [57][100/391]	lr: 1.000e-03, eta: 18:48:23, time: 1.757, data_time: 0.023, memory: 1498, loss: 25.7345, loss_KD: 25.6359
2022-08-06 16:11:24,837 - mmcls - INFO - Epoch [57][200/391]	lr: 1.000e-03, eta: 18:48:47, time: 1.771, data_time: 0.002, memory: 1498, loss: 25.7508, loss_KD: 25.6478
2022-08-06 16:14:21,861 - mmcls - INFO - Epoch [57][300/391]	lr: 1.000e-03, eta: 18:49:08, time: 1.770, data_time: 0.002, memory: 1498, loss: 25.7730, loss_KD: 25.6655
2022-08-06 16:17:13,359 - mmcls - INFO - Epoch(val) [57][79]	accuracy_top-1: 70.5100, accuracy_top-5: 91.4500
2022-08-06 16:20:11,195 - mmcls - INFO - Epoch [58][100/391]	lr: 1.000e-03, eta: 18:43:04, time: 1.776, data_time: 0.021, memory: 1498, loss: 25.7713, loss_KD: 25.6712
2022-08-06 16:23:07,232 - mmcls - INFO - Epoch [58][200/391]	lr: 1.000e-03, eta: 18:43:20, time: 1.760, data_time: 0.002, memory: 1498, loss: 25.7616, loss_KD: 25.6627
2022-08-06 16:26:09,270 - mmcls - INFO - Epoch [58][300/391]	lr: 1.000e-03, eta: 18:43:49, time: 1.820, data_time: 0.002, memory: 1498, loss: 25.7968, loss_KD: 25.6829
2022-08-06 16:29:12,989 - mmcls - INFO - Epoch(val) [58][79]	accuracy_top-1: 70.7200, accuracy_top-5: 91.3200
2022-08-06 16:32:55,186 - mmcls - INFO - Epoch [59][100/391]	lr: 1.000e-03, eta: 18:39:35, time: 2.220, data_time: 0.024, memory: 1498, loss: 25.7824, loss_KD: 25.6898
2022-08-06 16:35:45,618 - mmcls - INFO - Epoch [59][200/391]	lr: 1.000e-03, eta: 18:39:32, time: 1.705, data_time: 0.002, memory: 1498, loss: 25.7861, loss_KD: 25.6889
2022-08-06 16:38:26,263 - mmcls - INFO - Epoch [59][300/391]	lr: 1.000e-03, eta: 18:39:05, time: 1.606, data_time: 0.002, memory: 1498, loss: 25.8012, loss_KD: 25.6973
2022-08-06 16:41:10,325 - mmcls - INFO - Epoch(val) [59][79]	accuracy_top-1: 70.6100, accuracy_top-5: 91.3400
2022-08-06 16:44:14,045 - mmcls - INFO - Epoch [60][100/391]	lr: 1.000e-03, eta: 18:33:18, time: 1.836, data_time: 0.022, memory: 1498, loss: 25.7880, loss_KD: 25.6981
2022-08-06 16:47:19,624 - mmcls - INFO - Epoch [60][200/391]	lr: 1.000e-03, eta: 18:33:48, time: 1.856, data_time: 0.002, memory: 1498, loss: 25.8031, loss_KD: 25.7070
2022-08-06 16:50:34,912 - mmcls - INFO - Epoch [60][300/391]	lr: 1.000e-03, eta: 18:34:39, time: 1.953, data_time: 0.002, memory: 1498, loss: 25.8244, loss_KD: 25.7240
2022-08-06 16:53:27,815 - mmcls - INFO - Saving checkpoint at 60 epochs
2022-08-06 16:53:35,710 - mmcls - INFO - Epoch(val) [60][79]	accuracy_top-1: 70.8800, accuracy_top-5: 91.4900
2022-08-06 16:56:09,911 - mmcls - INFO - Epoch [61][100/391]	lr: 2.000e-04, eta: 18:27:43, time: 1.540, data_time: 0.022, memory: 1498, loss: 25.7817, loss_KD: 25.7074
2022-08-06 16:58:35,137 - mmcls - INFO - Epoch [61][200/391]	lr: 2.000e-04, eta: 18:26:35, time: 1.452, data_time: 0.002, memory: 1498, loss: 25.7821, loss_KD: 25.7111
2022-08-06 17:01:01,085 - mmcls - INFO - Epoch [61][300/391]	lr: 2.000e-04, eta: 18:25:29, time: 1.460, data_time: 0.002, memory: 1498, loss: 25.7687, loss_KD: 25.7011
2022-08-06 17:03:21,439 - mmcls - INFO - Epoch(val) [61][79]	accuracy_top-1: 72.0300, accuracy_top-5: 91.8600
2022-08-06 17:05:52,831 - mmcls - INFO - Epoch [62][100/391]	lr: 2.000e-04, eta: 18:18:32, time: 1.511, data_time: 0.021, memory: 1498, loss: 25.7673, loss_KD: 25.7042
2022-08-06 17:08:18,722 - mmcls - INFO - Epoch [62][200/391]	lr: 2.000e-04, eta: 18:17:25, time: 1.460, data_time: 0.003, memory: 1498, loss: 25.7562, loss_KD: 25.6938
2022-08-06 17:10:43,504 - mmcls - INFO - Epoch [62][300/391]	lr: 2.000e-04, eta: 18:16:16, time: 1.448, data_time: 0.002, memory: 1498, loss: 25.7676, loss_KD: 25.7026
2022-08-06 17:13:15,268 - mmcls - INFO - Epoch(val) [62][79]	accuracy_top-1: 71.9800, accuracy_top-5: 92.0100
2022-08-06 17:15:58,866 - mmcls - INFO - Epoch [63][100/391]	lr: 2.000e-04, eta: 18:09:51, time: 1.635, data_time: 0.021, memory: 1498, loss: 25.7476, loss_KD: 25.6875
2022-08-06 17:18:50,436 - mmcls - INFO - Epoch [63][200/391]	lr: 2.000e-04, eta: 18:09:40, time: 1.716, data_time: 0.002, memory: 1498, loss: 25.7644, loss_KD: 25.6990
2022-08-06 17:21:37,826 - mmcls - INFO - Epoch [63][300/391]	lr: 2.000e-04, eta: 18:09:18, time: 1.674, data_time: 0.002, memory: 1498, loss: 25.7749, loss_KD: 25.7106
2022-08-06 17:24:25,807 - mmcls - INFO - Epoch(val) [63][79]	accuracy_top-1: 71.8800, accuracy_top-5: 91.8800
2022-08-06 17:27:23,838 - mmcls - INFO - Epoch [64][100/391]	lr: 2.000e-04, eta: 18:03:27, time: 1.779, data_time: 0.022, memory: 1498, loss: 25.7673, loss_KD: 25.7062
2022-08-06 17:30:29,204 - mmcls - INFO - Epoch [64][200/391]	lr: 2.000e-04, eta: 18:03:43, time: 1.854, data_time: 0.002, memory: 1498, loss: 25.7711, loss_KD: 25.7087
2022-08-06 17:33:29,464 - mmcls - INFO - Epoch [64][300/391]	lr: 2.000e-04, eta: 18:03:46, time: 1.803, data_time: 0.002, memory: 1498, loss: 25.7738, loss_KD: 25.7121
2022-08-06 17:36:23,838 - mmcls - INFO - Epoch(val) [64][79]	accuracy_top-1: 72.2600, accuracy_top-5: 92.1000
2022-08-06 17:39:29,140 - mmcls - INFO - Epoch [65][100/391]	lr: 2.000e-04, eta: 17:58:11, time: 1.852, data_time: 0.024, memory: 1498, loss: 25.7727, loss_KD: 25.7103
2022-08-06 17:42:29,223 - mmcls - INFO - Epoch [65][200/391]	lr: 2.000e-04, eta: 17:58:11, time: 1.801, data_time: 0.002, memory: 1498, loss: 25.7742, loss_KD: 25.7133
2022-08-06 17:45:30,116 - mmcls - INFO - Epoch [65][300/391]	lr: 2.000e-04, eta: 17:58:12, time: 1.809, data_time: 0.002, memory: 1498, loss: 25.7636, loss_KD: 25.7020
2022-08-06 17:48:22,624 - mmcls - INFO - Epoch(val) [65][79]	accuracy_top-1: 72.2300, accuracy_top-5: 92.1700
2022-08-06 17:51:27,766 - mmcls - INFO - Epoch [66][100/391]	lr: 2.000e-04, eta: 17:52:38, time: 1.850, data_time: 0.022, memory: 1498, loss: 25.7719, loss_KD: 25.7127
2022-08-06 17:54:32,952 - mmcls - INFO - Epoch [66][200/391]	lr: 2.000e-04, eta: 17:52:45, time: 1.852, data_time: 0.002, memory: 1498, loss: 25.7765, loss_KD: 25.7146
2022-08-06 17:57:37,908 - mmcls - INFO - Epoch [66][300/391]	lr: 2.000e-04, eta: 17:52:50, time: 1.850, data_time: 0.002, memory: 1498, loss: 25.7777, loss_KD: 25.7165
2022-08-06 18:00:31,154 - mmcls - INFO - Epoch(val) [66][79]	accuracy_top-1: 71.9500, accuracy_top-5: 92.1600
2022-08-06 18:03:41,540 - mmcls - INFO - Epoch [67][100/391]	lr: 2.000e-04, eta: 17:47:27, time: 1.902, data_time: 0.024, memory: 1498, loss: 25.7621, loss_KD: 25.7040
2022-08-06 18:06:47,544 - mmcls - INFO - Epoch [67][200/391]	lr: 2.000e-04, eta: 17:47:32, time: 1.860, data_time: 0.003, memory: 1498, loss: 25.7809, loss_KD: 25.7214
2022-08-06 18:09:50,661 - mmcls - INFO - Epoch [67][300/391]	lr: 2.000e-04, eta: 17:47:30, time: 1.831, data_time: 0.002, memory: 1498, loss: 25.7695, loss_KD: 25.7106
2022-08-06 18:12:46,807 - mmcls - INFO - Epoch(val) [67][79]	accuracy_top-1: 71.6800, accuracy_top-5: 91.8700
2022-08-06 18:15:45,172 - mmcls - INFO - Epoch [68][100/391]	lr: 2.000e-04, eta: 17:41:43, time: 1.782, data_time: 0.022, memory: 1498, loss: 25.7718, loss_KD: 25.7141
2022-08-06 18:18:42,291 - mmcls - INFO - Epoch [68][200/391]	lr: 2.000e-04, eta: 17:41:27, time: 1.771, data_time: 0.002, memory: 1498, loss: 25.7780, loss_KD: 25.7177
2022-08-06 18:21:41,343 - mmcls - INFO - Epoch [68][300/391]	lr: 2.000e-04, eta: 17:41:14, time: 1.791, data_time: 0.002, memory: 1498, loss: 25.7856, loss_KD: 25.7259
2022-08-06 18:24:22,296 - mmcls - INFO - Epoch(val) [68][79]	accuracy_top-1: 71.7900, accuracy_top-5: 91.9600
2022-08-06 18:27:12,752 - mmcls - INFO - Epoch [69][100/391]	lr: 2.000e-04, eta: 17:35:13, time: 1.703, data_time: 0.021, memory: 1498, loss: 25.7739, loss_KD: 25.7162
2022-08-06 18:30:08,299 - mmcls - INFO - Epoch [69][200/391]	lr: 2.000e-04, eta: 17:34:51, time: 1.755, data_time: 0.002, memory: 1498, loss: 25.7802, loss_KD: 25.7218
2022-08-06 18:32:58,606 - mmcls - INFO - Epoch [69][300/391]	lr: 2.000e-04, eta: 17:34:18, time: 1.703, data_time: 0.002, memory: 1498, loss: 25.7828, loss_KD: 25.7225
2022-08-06 18:35:36,168 - mmcls - INFO - Epoch(val) [69][79]	accuracy_top-1: 72.1000, accuracy_top-5: 92.0600
2022-08-06 18:38:02,562 - mmcls - INFO - Epoch [70][100/391]	lr: 2.000e-04, eta: 17:27:34, time: 1.462, data_time: 0.021, memory: 1498, loss: 25.7732, loss_KD: 25.7174
2022-08-06 18:40:23,940 - mmcls - INFO - Epoch [70][200/391]	lr: 2.000e-04, eta: 17:26:06, time: 1.414, data_time: 0.002, memory: 1498, loss: 25.7938, loss_KD: 25.7342
2022-08-06 18:42:56,461 - mmcls - INFO - Epoch [70][300/391]	lr: 2.000e-04, eta: 17:24:58, time: 1.526, data_time: 0.002, memory: 1498, loss: 25.7753, loss_KD: 25.7167
2022-08-06 18:45:22,012 - mmcls - INFO - Saving checkpoint at 70 epochs
2022-08-06 18:45:31,067 - mmcls - INFO - Epoch(val) [70][79]	accuracy_top-1: 72.2800, accuracy_top-5: 92.3300
2022-08-06 18:48:18,726 - mmcls - INFO - Epoch [71][100/391]	lr: 2.000e-04, eta: 17:18:58, time: 1.676, data_time: 0.021, memory: 1498, loss: 25.7749, loss_KD: 25.7191
2022-08-06 18:51:23,420 - mmcls - INFO - Epoch [71][200/391]	lr: 2.000e-04, eta: 17:18:49, time: 1.847, data_time: 0.002, memory: 1498, loss: 25.7893, loss_KD: 25.7313
2022-08-06 18:54:23,526 - mmcls - INFO - Epoch [71][300/391]	lr: 2.000e-04, eta: 17:18:30, time: 1.801, data_time: 0.002, memory: 1498, loss: 25.7989, loss_KD: 25.7407
2022-08-06 18:57:16,875 - mmcls - INFO - Epoch(val) [71][79]	accuracy_top-1: 71.6300, accuracy_top-5: 91.8600
2022-08-06 19:00:14,937 - mmcls - INFO - Epoch [72][100/391]	lr: 2.000e-04, eta: 17:12:50, time: 1.780, data_time: 0.023, memory: 1498, loss: 25.7971, loss_KD: 25.7393
2022-08-06 19:03:15,335 - mmcls - INFO - Epoch [72][200/391]	lr: 2.000e-04, eta: 17:12:30, time: 1.804, data_time: 0.002, memory: 1498, loss: 25.7910, loss_KD: 25.7335
2022-08-06 19:06:18,761 - mmcls - INFO - Epoch [72][300/391]	lr: 2.000e-04, eta: 17:12:14, time: 1.834, data_time: 0.002, memory: 1498, loss: 25.7976, loss_KD: 25.7386
2022-08-06 19:09:14,683 - mmcls - INFO - Epoch(val) [72][79]	accuracy_top-1: 71.6800, accuracy_top-5: 92.0900
2022-08-06 19:12:20,381 - mmcls - INFO - Epoch [73][100/391]	lr: 2.000e-04, eta: 17:06:49, time: 1.856, data_time: 0.024, memory: 1498, loss: 25.7858, loss_KD: 25.7305
2022-08-06 19:15:27,694 - mmcls - INFO - Epoch [73][200/391]	lr: 2.000e-04, eta: 17:06:38, time: 1.873, data_time: 0.003, memory: 1498, loss: 25.7848, loss_KD: 25.7277
2022-08-06 19:18:35,812 - mmcls - INFO - Epoch [73][300/391]	lr: 2.000e-04, eta: 17:06:28, time: 1.881, data_time: 0.002, memory: 1498, loss: 25.7992, loss_KD: 25.7407
2022-08-06 19:21:33,818 - mmcls - INFO - Epoch(val) [73][79]	accuracy_top-1: 71.9100, accuracy_top-5: 91.9100
2022-08-06 19:24:39,928 - mmcls - INFO - Epoch [74][100/391]	lr: 2.000e-04, eta: 17:01:04, time: 1.860, data_time: 0.024, memory: 1498, loss: 25.7966, loss_KD: 25.7407
2022-08-06 19:27:42,427 - mmcls - INFO - Epoch [74][200/391]	lr: 2.000e-04, eta: 17:00:41, time: 1.825, data_time: 0.002, memory: 1498, loss: 25.8045, loss_KD: 25.7480
2022-08-06 19:30:47,987 - mmcls - INFO - Epoch [74][300/391]	lr: 2.000e-04, eta: 17:00:23, time: 1.856, data_time: 0.002, memory: 1498, loss: 25.7968, loss_KD: 25.7395
2022-08-06 19:33:52,436 - mmcls - INFO - Epoch(val) [74][79]	accuracy_top-1: 72.0900, accuracy_top-5: 91.9500
2022-08-06 19:36:59,394 - mmcls - INFO - Epoch [75][100/391]	lr: 2.000e-04, eta: 16:55:02, time: 1.868, data_time: 0.024, memory: 1498, loss: 25.7957, loss_KD: 25.7396
2022-08-06 19:40:03,014 - mmcls - INFO - Epoch [75][200/391]	lr: 2.000e-04, eta: 16:54:38, time: 1.836, data_time: 0.003, memory: 1498, loss: 25.7966, loss_KD: 25.7402
2022-08-06 19:43:10,976 - mmcls - INFO - Epoch [75][300/391]	lr: 2.000e-04, eta: 16:54:21, time: 1.880, data_time: 0.002, memory: 1498, loss: 25.8044, loss_KD: 25.7467
2022-08-06 19:46:11,216 - mmcls - INFO - Epoch(val) [75][79]	accuracy_top-1: 72.0300, accuracy_top-5: 92.2200
2022-08-06 19:49:14,990 - mmcls - INFO - Epoch [76][100/391]	lr: 2.000e-04, eta: 16:48:55, time: 1.836, data_time: 0.024, memory: 1498, loss: 25.7980, loss_KD: 25.7422
2022-08-06 19:52:22,418 - mmcls - INFO - Epoch [76][200/391]	lr: 2.000e-04, eta: 16:48:35, time: 1.874, data_time: 0.002, memory: 1498, loss: 25.8064, loss_KD: 25.7501
2022-08-06 19:55:31,245 - mmcls - INFO - Epoch [76][300/391]	lr: 2.000e-04, eta: 16:48:16, time: 1.888, data_time: 0.002, memory: 1498, loss: 25.8126, loss_KD: 25.7544
2022-08-06 19:58:37,149 - mmcls - INFO - Epoch(val) [76][79]	accuracy_top-1: 71.8100, accuracy_top-5: 92.2500
2022-08-06 20:01:49,899 - mmcls - INFO - Epoch [77][100/391]	lr: 2.000e-04, eta: 16:43:05, time: 1.926, data_time: 0.024, memory: 1498, loss: 25.8053, loss_KD: 25.7501
2022-08-06 20:04:58,002 - mmcls - INFO - Epoch [77][200/391]	lr: 2.000e-04, eta: 16:42:44, time: 1.881, data_time: 0.002, memory: 1498, loss: 25.8038, loss_KD: 25.7493
2022-08-06 20:08:04,432 - mmcls - INFO - Epoch [77][300/391]	lr: 2.000e-04, eta: 16:42:18, time: 1.864, data_time: 0.002, memory: 1498, loss: 25.8050, loss_KD: 25.7502
2022-08-06 20:11:02,865 - mmcls - INFO - Epoch(val) [77][79]	accuracy_top-1: 71.7200, accuracy_top-5: 92.0700
2022-08-06 20:14:08,408 - mmcls - INFO - Epoch [78][100/391]	lr: 2.000e-04, eta: 16:36:56, time: 1.854, data_time: 0.024, memory: 1498, loss: 25.8152, loss_KD: 25.7583
2022-08-06 20:17:38,914 - mmcls - INFO - Epoch [78][200/391]	lr: 2.000e-04, eta: 16:37:07, time: 2.105, data_time: 0.003, memory: 1498, loss: 25.8063, loss_KD: 25.7514
2022-08-06 20:20:52,837 - mmcls - INFO - Epoch [78][300/391]	lr: 2.000e-04, eta: 16:36:50, time: 1.939, data_time: 0.002, memory: 1498, loss: 25.8317, loss_KD: 25.7730
2022-08-06 20:23:54,169 - mmcls - INFO - Epoch(val) [78][79]	accuracy_top-1: 72.2400, accuracy_top-5: 92.2500
2022-08-06 20:27:03,273 - mmcls - INFO - Epoch [79][100/391]	lr: 2.000e-04, eta: 16:31:33, time: 1.890, data_time: 0.024, memory: 1498, loss: 25.8165, loss_KD: 25.7619
2022-08-06 20:30:07,132 - mmcls - INFO - Epoch [79][200/391]	lr: 2.000e-04, eta: 16:30:59, time: 1.838, data_time: 0.002, memory: 1498, loss: 25.8045, loss_KD: 25.7508
2022-08-06 20:33:16,254 - mmcls - INFO - Epoch [79][300/391]	lr: 2.000e-04, eta: 16:30:33, time: 1.891, data_time: 0.002, memory: 1498, loss: 25.8277, loss_KD: 25.7684
2022-08-06 20:36:11,632 - mmcls - INFO - Epoch(val) [79][79]	accuracy_top-1: 72.1500, accuracy_top-5: 92.1200
2022-08-06 20:39:22,564 - mmcls - INFO - Epoch [80][100/391]	lr: 2.000e-04, eta: 16:25:19, time: 1.908, data_time: 0.024, memory: 1498, loss: 25.8138, loss_KD: 25.7584
2022-08-06 20:42:29,789 - mmcls - INFO - Epoch [80][200/391]	lr: 2.000e-04, eta: 16:24:48, time: 1.872, data_time: 0.002, memory: 1498, loss: 25.8264, loss_KD: 25.7694
2022-08-06 20:45:36,166 - mmcls - INFO - Epoch [80][300/391]	lr: 2.000e-04, eta: 16:24:14, time: 1.863, data_time: 0.002, memory: 1498, loss: 25.8288, loss_KD: 25.7723
2022-08-06 20:48:31,678 - mmcls - INFO - Saving checkpoint at 80 epochs
2022-08-06 20:48:44,207 - mmcls - INFO - Epoch(val) [80][79]	accuracy_top-1: 71.7800, accuracy_top-5: 92.0300
2022-08-06 20:51:55,443 - mmcls - INFO - Epoch [81][100/391]	lr: 2.000e-04, eta: 16:19:02, time: 1.911, data_time: 0.024, memory: 1498, loss: 25.8215, loss_KD: 25.7673
2022-08-06 20:54:59,246 - mmcls - INFO - Epoch [81][200/391]	lr: 2.000e-04, eta: 16:18:23, time: 1.838, data_time: 0.002, memory: 1498, loss: 25.8285, loss_KD: 25.7730
2022-08-06 20:58:12,123 - mmcls - INFO - Epoch [81][300/391]	lr: 2.000e-04, eta: 16:17:56, time: 1.929, data_time: 0.003, memory: 1498, loss: 25.8289, loss_KD: 25.7723
2022-08-06 21:01:10,837 - mmcls - INFO - Epoch(val) [81][79]	accuracy_top-1: 71.9900, accuracy_top-5: 91.8600
2022-08-06 21:04:19,779 - mmcls - INFO - Epoch [82][100/391]	lr: 2.000e-04, eta: 16:12:40, time: 1.888, data_time: 0.024, memory: 1498, loss: 25.8249, loss_KD: 25.7704
2022-08-06 21:07:24,065 - mmcls - INFO - Epoch [82][200/391]	lr: 2.000e-04, eta: 16:12:00, time: 1.843, data_time: 0.002, memory: 1498, loss: 25.8274, loss_KD: 25.7722
2022-08-06 21:10:28,566 - mmcls - INFO - Epoch [82][300/391]	lr: 2.000e-04, eta: 16:11:19, time: 1.845, data_time: 0.003, memory: 1498, loss: 25.8346, loss_KD: 25.7786
2022-08-06 21:13:24,763 - mmcls - INFO - Epoch(val) [82][79]	accuracy_top-1: 71.8400, accuracy_top-5: 92.0300
2022-08-06 21:16:34,732 - mmcls - INFO - Epoch [83][100/391]	lr: 2.000e-04, eta: 16:06:05, time: 1.898, data_time: 0.024, memory: 1498, loss: 25.8301, loss_KD: 25.7766
2022-08-06 21:19:39,096 - mmcls - INFO - Epoch [83][200/391]	lr: 2.000e-04, eta: 16:05:22, time: 1.844, data_time: 0.002, memory: 1498, loss: 25.8252, loss_KD: 25.7704
2022-08-06 21:22:48,200 - mmcls - INFO - Epoch [83][300/391]	lr: 2.000e-04, eta: 16:04:46, time: 1.891, data_time: 0.002, memory: 1498, loss: 25.8338, loss_KD: 25.7765
2022-08-06 21:25:51,336 - mmcls - INFO - Epoch(val) [83][79]	accuracy_top-1: 72.1100, accuracy_top-5: 92.1900
2022-08-06 21:29:01,552 - mmcls - INFO - Epoch [84][100/391]	lr: 2.000e-04, eta: 15:59:33, time: 1.901, data_time: 0.024, memory: 1498, loss: 25.8284, loss_KD: 25.7746
2022-08-06 21:32:11,041 - mmcls - INFO - Epoch [84][200/391]	lr: 2.000e-04, eta: 15:58:55, time: 1.895, data_time: 0.002, memory: 1498, loss: 25.8391, loss_KD: 25.7855
2022-08-06 21:35:18,049 - mmcls - INFO - Epoch [84][300/391]	lr: 2.000e-04, eta: 15:58:13, time: 1.870, data_time: 0.002, memory: 1498, loss: 25.8311, loss_KD: 25.7753
2022-08-06 21:38:17,862 - mmcls - INFO - Epoch(val) [84][79]	accuracy_top-1: 71.8800, accuracy_top-5: 92.0500
2022-08-06 21:41:28,764 - mmcls - INFO - Epoch [85][100/391]	lr: 2.000e-04, eta: 15:53:01, time: 1.908, data_time: 0.024, memory: 1498, loss: 25.8414, loss_KD: 25.7880
2022-08-06 21:44:34,785 - mmcls - INFO - Epoch [85][200/391]	lr: 2.000e-04, eta: 15:52:17, time: 1.860, data_time: 0.002, memory: 1498, loss: 25.8339, loss_KD: 25.7817
2022-08-06 21:47:47,327 - mmcls - INFO - Epoch [85][300/391]	lr: 2.000e-04, eta: 15:51:40, time: 1.925, data_time: 0.002, memory: 1498, loss: 25.8455, loss_KD: 25.7901
2022-08-06 21:50:53,871 - mmcls - INFO - Epoch(val) [85][79]	accuracy_top-1: 72.2400, accuracy_top-5: 92.1400
2022-08-06 21:54:05,627 - mmcls - INFO - Epoch [86][100/391]	lr: 2.000e-04, eta: 15:46:30, time: 1.916, data_time: 0.024, memory: 1498, loss: 25.8415, loss_KD: 25.7879
2022-08-06 21:57:17,227 - mmcls - INFO - Epoch [86][200/391]	lr: 2.000e-04, eta: 15:45:50, time: 1.916, data_time: 0.002, memory: 1498, loss: 25.8392, loss_KD: 25.7843
2022-08-06 22:00:29,069 - mmcls - INFO - Epoch [86][300/391]	lr: 2.000e-04, eta: 15:45:10, time: 1.919, data_time: 0.003, memory: 1498, loss: 25.8424, loss_KD: 25.7878
2022-08-06 22:03:31,902 - mmcls - INFO - Epoch(val) [86][79]	accuracy_top-1: 71.8800, accuracy_top-5: 92.2900
2022-08-06 22:06:45,310 - mmcls - INFO - Epoch [87][100/391]	lr: 2.000e-04, eta: 15:40:03, time: 1.933, data_time: 0.024, memory: 1498, loss: 25.8483, loss_KD: 25.7918
2022-08-06 22:09:56,975 - mmcls - INFO - Epoch [87][200/391]	lr: 2.000e-04, eta: 15:39:21, time: 1.916, data_time: 0.002, memory: 1498, loss: 25.8489, loss_KD: 25.7938
2022-08-06 22:13:11,479 - mmcls - INFO - Epoch [87][300/391]	lr: 2.000e-04, eta: 15:38:42, time: 1.945, data_time: 0.003, memory: 1498, loss: 25.8399, loss_KD: 25.7857
2022-08-06 22:16:17,543 - mmcls - INFO - Epoch(val) [87][79]	accuracy_top-1: 71.7500, accuracy_top-5: 92.0900
2022-08-06 22:19:32,632 - mmcls - INFO - Epoch [88][100/391]	lr: 2.000e-04, eta: 15:33:37, time: 1.950, data_time: 0.024, memory: 1498, loss: 25.8518, loss_KD: 25.7974
2022-08-06 22:22:47,900 - mmcls - INFO - Epoch [88][200/391]	lr: 2.000e-04, eta: 15:32:58, time: 1.953, data_time: 0.002, memory: 1498, loss: 25.8475, loss_KD: 25.7942
2022-08-06 22:26:00,186 - mmcls - INFO - Epoch [88][300/391]	lr: 2.000e-04, eta: 15:32:14, time: 1.923, data_time: 0.002, memory: 1498, loss: 25.8494, loss_KD: 25.7948
2022-08-06 22:29:01,973 - mmcls - INFO - Epoch(val) [88][79]	accuracy_top-1: 71.7000, accuracy_top-5: 91.9200
2022-08-06 22:32:15,347 - mmcls - INFO - Epoch [89][100/391]	lr: 2.000e-04, eta: 15:27:07, time: 1.933, data_time: 0.024, memory: 1498, loss: 25.8481, loss_KD: 25.7945
2022-08-06 22:35:27,351 - mmcls - INFO - Epoch [89][200/391]	lr: 2.000e-04, eta: 15:26:21, time: 1.920, data_time: 0.002, memory: 1498, loss: 25.8576, loss_KD: 25.8043
2022-08-06 22:38:39,579 - mmcls - INFO - Epoch [89][300/391]	lr: 2.000e-04, eta: 15:25:34, time: 1.922, data_time: 0.002, memory: 1498, loss: 25.8652, loss_KD: 25.8098
2022-08-06 22:41:43,727 - mmcls - INFO - Epoch(val) [89][79]	accuracy_top-1: 71.9800, accuracy_top-5: 92.1600
2022-08-06 22:44:56,592 - mmcls - INFO - Epoch [90][100/391]	lr: 2.000e-04, eta: 15:20:27, time: 1.928, data_time: 0.024, memory: 1498, loss: 25.8623, loss_KD: 25.8091
2022-08-06 22:48:09,344 - mmcls - INFO - Epoch [90][200/391]	lr: 2.000e-04, eta: 15:19:40, time: 1.927, data_time: 0.002, memory: 1498, loss: 25.8576, loss_KD: 25.8042
2022-08-06 22:51:20,153 - mmcls - INFO - Epoch [90][300/391]	lr: 2.000e-04, eta: 15:18:50, time: 1.908, data_time: 0.003, memory: 1498, loss: 25.8643, loss_KD: 25.8100
2022-08-06 22:54:14,921 - mmcls - INFO - Saving checkpoint at 90 epochs
2022-08-06 22:54:27,983 - mmcls - INFO - Epoch(val) [90][79]	accuracy_top-1: 72.1800, accuracy_top-5: 92.0000
2022-08-06 22:57:43,935 - mmcls - INFO - Epoch [91][100/391]	lr: 2.000e-04, eta: 15:13:46, time: 1.959, data_time: 0.024, memory: 1498, loss: 25.8566, loss_KD: 25.8036
2022-08-06 23:00:57,111 - mmcls - INFO - Epoch [91][200/391]	lr: 2.000e-04, eta: 15:12:58, time: 1.932, data_time: 0.002, memory: 1498, loss: 25.8696, loss_KD: 25.8157
2022-08-06 23:04:10,660 - mmcls - INFO - Epoch [91][300/391]	lr: 2.000e-04, eta: 15:12:09, time: 1.935, data_time: 0.002, memory: 1498, loss: 25.8640, loss_KD: 25.8080
2022-08-06 23:07:17,434 - mmcls - INFO - Epoch(val) [91][79]	accuracy_top-1: 72.3900, accuracy_top-5: 92.3200
2022-08-06 23:10:32,116 - mmcls - INFO - Epoch [92][100/391]	lr: 2.000e-04, eta: 15:07:04, time: 1.946, data_time: 0.024, memory: 1498, loss: 25.8653, loss_KD: 25.8130
2022-08-06 23:13:49,885 - mmcls - INFO - Epoch [92][200/391]	lr: 2.000e-04, eta: 15:06:19, time: 1.978, data_time: 0.002, memory: 1498, loss: 25.8706, loss_KD: 25.8182
2022-08-06 23:17:01,951 - mmcls - INFO - Epoch [92][300/391]	lr: 2.000e-04, eta: 15:05:26, time: 1.921, data_time: 0.002, memory: 1498, loss: 25.8720, loss_KD: 25.8172
2022-08-06 23:20:06,998 - mmcls - INFO - Epoch(val) [92][79]	accuracy_top-1: 72.4000, accuracy_top-5: 92.3800
2022-08-06 23:23:24,187 - mmcls - INFO - Epoch [93][100/391]	lr: 2.000e-04, eta: 15:00:25, time: 1.971, data_time: 0.024, memory: 1498, loss: 25.8699, loss_KD: 25.8169
2022-08-06 23:26:36,936 - mmcls - INFO - Epoch [93][200/391]	lr: 2.000e-04, eta: 14:59:31, time: 1.927, data_time: 0.002, memory: 1498, loss: 25.8666, loss_KD: 25.8129
2022-08-06 23:29:49,708 - mmcls - INFO - Epoch [93][300/391]	lr: 2.000e-04, eta: 14:58:37, time: 1.928, data_time: 0.002, memory: 1498, loss: 25.8850, loss_KD: 25.8306
2022-08-06 23:32:55,060 - mmcls - INFO - Epoch(val) [93][79]	accuracy_top-1: 71.8500, accuracy_top-5: 92.1300
2022-08-06 23:36:12,305 - mmcls - INFO - Epoch [94][100/391]	lr: 2.000e-04, eta: 14:53:36, time: 1.971, data_time: 0.024, memory: 1498, loss: 25.8682, loss_KD: 25.8158
2022-08-06 23:39:28,669 - mmcls - INFO - Epoch [94][200/391]	lr: 2.000e-04, eta: 14:52:45, time: 1.964, data_time: 0.002, memory: 1498, loss: 25.8688, loss_KD: 25.8155
2022-08-06 23:42:46,193 - mmcls - INFO - Epoch [94][300/391]	lr: 2.000e-04, eta: 14:51:55, time: 1.975, data_time: 0.002, memory: 1498, loss: 25.8759, loss_KD: 25.8225
2022-08-06 23:45:57,575 - mmcls - INFO - Epoch(val) [94][79]	accuracy_top-1: 71.8900, accuracy_top-5: 92.2300
2022-08-06 23:49:15,626 - mmcls - INFO - Epoch [95][100/391]	lr: 2.000e-04, eta: 14:46:54, time: 1.979, data_time: 0.024, memory: 1498, loss: 25.8755, loss_KD: 25.8233
2022-08-06 23:52:33,642 - mmcls - INFO - Epoch [95][200/391]	lr: 2.000e-04, eta: 14:46:03, time: 1.980, data_time: 0.002, memory: 1498, loss: 25.8798, loss_KD: 25.8265
2022-08-06 23:55:50,357 - mmcls - INFO - Epoch [95][300/391]	lr: 2.000e-04, eta: 14:45:09, time: 1.967, data_time: 0.002, memory: 1498, loss: 25.8711, loss_KD: 25.8184
2022-08-06 23:59:01,973 - mmcls - INFO - Epoch(val) [95][79]	accuracy_top-1: 72.2100, accuracy_top-5: 92.2500
2022-08-07 00:02:21,053 - mmcls - INFO - Epoch [96][100/391]	lr: 2.000e-04, eta: 14:40:11, time: 1.990, data_time: 0.024, memory: 1498, loss: 25.8800, loss_KD: 25.8281
2022-08-07 00:05:39,530 - mmcls - INFO - Epoch [96][200/391]	lr: 2.000e-04, eta: 14:39:18, time: 1.985, data_time: 0.002, memory: 1498, loss: 25.8807, loss_KD: 25.8267
2022-08-07 00:08:54,031 - mmcls - INFO - Epoch [96][300/391]	lr: 2.000e-04, eta: 14:38:20, time: 1.945, data_time: 0.002, memory: 1498, loss: 25.8805, loss_KD: 25.8259
2022-08-07 00:12:02,278 - mmcls - INFO - Epoch(val) [96][79]	accuracy_top-1: 71.6000, accuracy_top-5: 91.7700
2022-08-07 00:15:20,771 - mmcls - INFO - Epoch [97][100/391]	lr: 2.000e-04, eta: 14:33:20, time: 1.984, data_time: 0.024, memory: 1498, loss: 25.8787, loss_KD: 25.8280
2022-08-07 00:18:39,222 - mmcls - INFO - Epoch [97][200/391]	lr: 2.000e-04, eta: 14:32:26, time: 1.984, data_time: 0.002, memory: 1498, loss: 25.8855, loss_KD: 25.8315
2022-08-07 00:21:56,565 - mmcls - INFO - Epoch [97][300/391]	lr: 2.000e-04, eta: 14:31:29, time: 1.973, data_time: 0.002, memory: 1498, loss: 25.8845, loss_KD: 25.8300
2022-08-07 00:25:10,065 - mmcls - INFO - Epoch(val) [97][79]	accuracy_top-1: 71.9900, accuracy_top-5: 92.0200
2022-08-07 00:28:29,325 - mmcls - INFO - Epoch [98][100/391]	lr: 2.000e-04, eta: 14:26:30, time: 1.991, data_time: 0.024, memory: 1498, loss: 25.8885, loss_KD: 25.8365
2022-08-07 00:31:48,500 - mmcls - INFO - Epoch [98][200/391]	lr: 2.000e-04, eta: 14:25:34, time: 1.992, data_time: 0.002, memory: 1498, loss: 25.8794, loss_KD: 25.8266
2022-08-07 00:35:05,485 - mmcls - INFO - Epoch [98][300/391]	lr: 2.000e-04, eta: 14:24:35, time: 1.970, data_time: 0.002, memory: 1498, loss: 25.8957, loss_KD: 25.8430
2022-08-07 00:38:10,717 - mmcls - INFO - Epoch(val) [98][79]	accuracy_top-1: 72.1300, accuracy_top-5: 92.1500
2022-08-07 00:41:30,345 - mmcls - INFO - Epoch [99][100/391]	lr: 2.000e-04, eta: 14:19:37, time: 1.995, data_time: 0.024, memory: 1498, loss: 25.8940, loss_KD: 25.8403
2022-08-07 00:44:49,216 - mmcls - INFO - Epoch [99][200/391]	lr: 2.000e-04, eta: 14:18:39, time: 1.989, data_time: 0.002, memory: 1498, loss: 25.8886, loss_KD: 25.8360
2022-08-07 00:48:04,694 - mmcls - INFO - Epoch [99][300/391]	lr: 2.000e-04, eta: 14:17:36, time: 1.955, data_time: 0.002, memory: 1498, loss: 25.8892, loss_KD: 25.8374
2022-08-07 00:51:10,385 - mmcls - INFO - Epoch(val) [99][79]	accuracy_top-1: 72.2400, accuracy_top-5: 92.2100
2022-08-07 00:54:28,326 - mmcls - INFO - Epoch [100][100/391]	lr: 2.000e-04, eta: 14:12:37, time: 1.978, data_time: 0.024, memory: 1498, loss: 25.9009, loss_KD: 25.8488
2022-08-07 00:57:43,329 - mmcls - INFO - Epoch [100][200/391]	lr: 2.000e-04, eta: 14:11:33, time: 1.950, data_time: 0.002, memory: 1498, loss: 25.8944, loss_KD: 25.8417
2022-08-07 01:01:02,496 - mmcls - INFO - Epoch [100][300/391]	lr: 2.000e-04, eta: 14:10:32, time: 1.992, data_time: 0.002, memory: 1498, loss: 25.8985, loss_KD: 25.8452
2022-08-07 01:04:01,503 - mmcls - INFO - Saving checkpoint at 100 epochs
2022-08-07 01:04:11,742 - mmcls - INFO - Epoch(val) [100][79]	accuracy_top-1: 72.3200, accuracy_top-5: 92.2000
2022-08-07 01:07:33,650 - mmcls - INFO - Epoch [101][100/391]	lr: 2.000e-04, eta: 14:05:37, time: 2.018, data_time: 0.024, memory: 1498, loss: 25.9045, loss_KD: 25.8512
